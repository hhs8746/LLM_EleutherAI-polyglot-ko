{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580049c-a5f0-42c7-8890-2b654d0ebf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4f76c-04b1-4b5c-8dba-fbe363d134fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"beomi/KoAlpaca-v1.1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24438c0-007a-4d1b-a3c3-c2cb8de49cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55358a0b-e0ae-4056-b0f9-a8f694e01465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data\n",
    "# data = data.map(\n",
    "#     lambda x:\n",
    "#     {'text': f\"### 명령어: {x['instruction']}\\n\\n###맥락: {x['input']}\\n\\n### 답변: {x['output']}<|endoftext|>\" }\n",
    "#     if x['input'] else\n",
    "#     {'text':f\"### 명령어: {x['instruction']}\\n\\n### 답변: {x['output']}<|endoftext|>\"},\n",
    "# )\n",
    "# data\n",
    "data = data.map(\n",
    "    lambda x: {'text': f\"### 질문: {x['instruction']}\\n\\n### 답변: {x['output']}<|endoftext|>\" }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e9682-aca4-4f72-801f-d415912a6f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"EleutherAI/polyglot-ko-5.8b\"  # safetensors 컨버팅된 레포\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_use_double_quant=True,\n",
    "    bnb_8bit_quant_type=\"nf4\",\n",
    "    bnb_8bit_compute_dtype=torch.bfloat16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b297ed-a42e-45bd-a3af-afedb4a60fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db44638-e387-43ba-b51a-d385bc5b8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda samples: tokenizer(samples[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecfad3-adb6-49dc-85fb-9b8c695e72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba056da-78eb-4163-aeb9-030c371acd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8b4b8-c072-4fc6-8128-41f06a1722d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=12,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451ea32-1560-4114-b370-ac7b0bdf3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_key_value\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595cb76-47e6-4700-9238-6f25f5960cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec93c315-d373-4cb2-bffd-0fc67ce0dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model1.config.use_cache = True\n",
    "# silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c31d62-0258-45b0-a570-c6cfc2f27122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    gened = model1.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 질문: {x}\\n\\n### 답변:\",\n",
    "            return_tensors='pt',\n",
    "            return_token_type_ids=False\n",
    "        ).to(0),\n",
    "        max_new_tokens=200,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff972148-357f-422e-b0dc-75f1167d7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen('학교행정 및 경영, 보건 주제의 책을 추천해줘')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
